{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mveer1/speech_to_text_api/blob/main/Speech_to_text_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d9Pcdg5yEja"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooQepzjAFgcV",
        "outputId": "44f51d52-db6a-48e4-890b-a8640fd42329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0NyozDwd0_v"
      },
      "outputs": [],
      "source": [
        "# %cd /content\n",
        "# !git clone https://Saikumar13:saireddy_12@bitbucket.org/Saikumar13/video_understanding.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrcZ4Wj3fbmE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#os.chdir(\"/content/drive/MyDrive/streamn/video_understanding\")\n",
        "os.chdir(\"/content/drive/MyDrive/keywords_for_API\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKefAYKlf4Fz",
        "outputId": "5a1ab038-0b1e-45c9-a1d0-f59de42aefef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cropped_image\t     __pycache__\ttemp.mp4\t  tmp\n",
            "hitapi.py\t     requirements.txt\ttemp.wav\n",
            "metadata_extraction  speech_to_text.py\ttext_recognition\n"
          ]
        }
      ],
      "source": [
        "!ls -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpS3m8xZe9TN",
        "outputId": "f2ccbdfc-a562-4edc-f30d-28de2af3be8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed PyYAML-6.0 addict-2.4.0 anyio-3.5.0 asgiref-3.5.0 dataclasses-0.6 fastapi-0.73.0 ftfy-6.0.3 gunicorn-20.1.0 h11-0.13.0 httptools-0.3.0 huggingface-hub-0.4.0 install-1.3.5 jellyfish-0.9.0 langcodes-3.3.0 mmcv-1.4.4 pathy-0.6.1 pyahocorasick-1.4.2 pydantic-1.9.0 pyngrok-5.1.0 pyspellchecker-0.6.3 python-multipart-0.0.5 rapidfuzz-1.9.1 regex-2022.1.18 sacremoses-0.0.47 segtok-1.5.11 sentence-transformers-2.1.0 sentencepiece-0.1.96 sniffio-1.2.0 spacy-legacy-3.0.8 spacy-loggers-1.0.1 starlette-0.17.1 tokenizers-0.11.4 transformers-4.16.1 typer-0.4.0 uvicorn-0.17.1 uvloop-0.16.0 wordfreq-2.5.1 yake-0.4.8 yapf-0.32.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA3o1hQlwvrg"
      },
      "source": [
        "changes from sai's repo:\n",
        "1. main_fn\n",
        "2. prediction_utils\n",
        "3. final_metadata_ex\n",
        "4. requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVfmhCKAxvKh"
      },
      "source": [
        "## Main Code\n",
        "\n",
        "```\n",
        "two end points, \n",
        "1. one will accept a media file video or audio, will return a transcript (additonal functionality of adding words), \n",
        "2. another will be,  accept a video, run ocr, get the top keywords, send them to speech_to_text, return the transcript.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install --upgrade ipykernel"
      ],
      "metadata": {
        "id": "rIWAiWADLfPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bb5VrUH16Lyu",
        "outputId": "29f55a73-0d9f-4413-c276-ae8f04d12627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/Cython/Distutils/old_build_ext.py:41: UserWarning: Cython.Distutils.old_build_ext does not properly handle dependencies and is deprecated.\n",
            "  \"Cython.Distutils.old_build_ext does not properly handle dependencies \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Loading weights from checkpoint (/content/drive/.shortcut-targets-by-id/18dTQSKBXGddS0qBkYgEe6O-EC1wJDREG/keywords_for_API/text_recognition/Pretrained_Models/craft_mlt_25k.pth)\n",
            "loading pretrained model from /content/drive/.shortcut-targets-by-id/18dTQSKBXGddS0qBkYgEe6O-EC1wJDREG/keywords_for_API/text_recognition/Pretrained_Models/TPS-ResNet-BiLSTM-Attn-case-sensitive.pth\n",
            "---Model Loaded ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-5-f9e0176e1ab0>\", line 96, in <module>\n",
            "    ngrok_tunnel = ngrok.connect(8081)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyngrok/ngrok.py\", line 251, in connect\n",
            "    api_url = get_ngrok_process(pyngrok_config).api_url\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyngrok/ngrok.py\", line 162, in get_ngrok_process\n",
            "    return process.get_process(pyngrok_config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyngrok/process.py\", line 295, in get_process\n",
            "    return _start_process(pyngrok_config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyngrok/process.py\", line 468, in _start_process\n",
            "    raise PyngrokNgrokError(\"The ngrok process was unable to start.\", ngrok_process.logs)\n",
            "pyngrok.exception.PyngrokNgrokError: The ngrok process was unable to start.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'PyngrokNgrokError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import uvicorn\n",
        "import traceback\n",
        "from fastapi import FastAPI, File, UploadFile, Form\n",
        "from typing import List,Optional\n",
        "\n",
        "# %cd /content/video_understanding/\n",
        "from text_recognition.main_fn import GenTextOutput, process_input\n",
        "from metadata_extraction.final_metadata_extraction import metadata_main\n",
        "from speech_to_text import get_transcript\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "app = FastAPI(debug=True)\n",
        "\n",
        "debug = False\n",
        "\n",
        "from time import time\n",
        "\n",
        "@app.post(\"/main_transcript/\")\n",
        "def get_transcript_api(file: Optional[UploadFile] = File(None), text: Optional[str] = Form(None)):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        file: file to be uploaded\n",
        "    function: \n",
        "        this function will accept a media file video or audio, will return a transcript.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        keywords = []\n",
        "        if text:\n",
        "            keywords = text.split(\",\")\n",
        "        \n",
        "        print(\"For Video:\", file.filename, end='')\n",
        "        #save the file to a temp location at file_path\n",
        "        if file:\n",
        "            if not os.path.exists(\"./tmp/\"):\n",
        "                os.mkdir(\"./tmp/\")\n",
        "            file_path = os.path.join(\"./tmp/\" , file.filename)\n",
        "            # if debug: print(\"Saving the file temporarily at:\", file_path)\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                f.write(file.file.read())\n",
        "        \n",
        "        transcript, num_speakers =  get_transcript(file_path, keywords)\n",
        "        print(\"Transcript without keywords:\", transcript, \"LEN:\", len(transcript))\n",
        "        print(\"\\n\\n\")\n",
        "    except Exception as e:\n",
        "        if debug: print(\"error:\", e)\n",
        "        traceback.print_exc()\n",
        "    return transcript\n",
        "\n",
        "\n",
        "@app.post(\"/transcript_through_video/\")\n",
        "def get_transcript_through_video(file: Optional[UploadFile] = File(None)):\n",
        "# def get_transcript_through_video(video_path=\"\"):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        file: video file to be uploaded, mp4 or ts\n",
        "\n",
        "    function: \n",
        "        this function will accept a video, run ocr on the video, get the top keywords, send them to speech_to_text, return the transcript.\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"a\")\n",
        "    time.sleep(5)\n",
        "\n",
        "    image_list , frame_timestamps , is_video , destination = process_input(files=[file])#, video_path=file_path)\n",
        "    text_output = GenTextOutput(image_list = image_list, frame_timestamps= frame_timestamps)    \n",
        "    if debug: print(\"TEXT OUTPUT:\", text_output)\n",
        "    print(\"b\")\n",
        "    time.sleep(5)\n",
        "\n",
        "    keywords_dict = metadata_main( frames_data = text_output)\n",
        "    keywords = set()\n",
        "    for key in keywords_dict:\n",
        "        keywords.add(key)\n",
        "    if debug: print(\"FINISHED:\" , keywords)\n",
        "    print(\"c\")\n",
        "    time.sleep(5)\n",
        "    input_file_name = destination\n",
        "    output_file_name  = f\"{input_file_name.split('.')[0]}.wav\"\n",
        "    ffmpeg_cmd = f\"ffmpeg -y -i {input_file_name} {output_file_name}\"\n",
        "    os.system(ffmpeg_cmd)\n",
        "    print(\"d\")    \n",
        "    time.sleep(5)\n",
        "\n",
        "    transcript, num_speakers =  get_transcript(output_file_name, list(keywords))\n",
        "    if debug: print(\"GOT TRANSCRIPT:\", transcript)\n",
        "    if debug: print(\"NUM of Speakers:\", num_speakers)\n",
        "    print(\"For Video:\", file.filename, \"Transcript with keywords:[\", keywords, \"]  Transcript:\", transcript, \"LEN:\", len(transcript))\n",
        "    print(\"\\n\\n\\n\\n\\n\")\n",
        "    # return {\"transcript\" :transcript, \"Num_speakers\": num_speakers}\n",
        "\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8081)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "\n",
        "uvicorn.run(app, host='0.0.0.0', port=8081)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4UYthzmx5cC"
      },
      "source": [
        "\n",
        "## Test Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuchoz06x8p_"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8081)\n",
        "print('Public URL:', ngrok_tunnel.public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDl-gj3h0h01"
      },
      "outputs": [],
      "source": [
        "def hit_text_api(video_path,files_passed=[],frame_timestamps=[],url=adObj.TextApiIP):\n",
        "    if video_path:\n",
        "        params = {'video_path':video_path}\n",
        "    else:\n",
        "        params=None\n",
        "    #files\n",
        "    files=[]\n",
        "    if files_passed:\n",
        "        for fle in files_passed:\n",
        "            file_extension=fle.split('/')[-1].split('.')[-1]\n",
        "            if 'm' not in file_extension:\n",
        "                files.append(('files',(fle.split('/')[-1],open(fle,'rb'),'image/png')))#('files',(image_name,open image,type))\n",
        "            #if its a video\n",
        "            else:\n",
        "                files = {'files':open(fle,'rb')}\n",
        "    else:\n",
        "        files=None\n",
        "    if frame_timestamps:\n",
        "        data = {'frame_timestamps': frame_timestamps }\n",
        "    else:\n",
        "        data=None\n",
        "    logging.info(\"api inputs: data {} , parmas {} , files={}\".format(data,params,files))\n",
        "    response = requests.post(url, params=params, data=data,files=files)\n",
        "    #logging.info(\"{}\".format(response.text))\n",
        "    return json.loads(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG5Ar6tUKdAV"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MECmaX6nx_2j"
      },
      "outputs": [],
      "source": [
        "# from lib2to3.pgen2.token import OP\n",
        "# import os\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, File, UploadFile, Form, Request, Body\n",
        "\n",
        "from typing import List,Optional\n",
        "# from typing import Any, Dict, AnyStr, List, Union\n",
        "# from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi import FastAPI, File, UploadFile,Form, Request,Body\n",
        "# from text_recognition.main_fn import GenTextOutput , process_input\n",
        "from pyngrok import ngrok\n",
        "from speech_to_text import get_transcript, words_to_add\n",
        "\n",
        "app = FastAPI(debug=False)\n",
        "\n",
        "#two end points: \n",
        "#    two end points, one will accept a media file video or audio, will return a transcript (additonal functionality of adding words), \n",
        "#                    another will be,  accept a video, run ocr, get the top keywords, send them to speech_to_text, return the transcript.\n",
        "\n",
        "@app.post(\"/main_transcript/\")\n",
        "def get_transcript_api(file: Optional[UploadFile] = File(None), text: Optional[str] = Form(None)):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        file: file to be uploaded\n",
        "\n",
        "    function: \n",
        "        this function will accept a media file video or audio, will return a transcript.\n",
        "    \"\"\"\n",
        "    print(type(file))\n",
        "    print(text)\n",
        "    if text:\n",
        "        keywords = text.split(\",\")\n",
        "    # transcript, _ =  get_transcript(file)\n",
        "    # return transcript\n",
        "\n",
        "@app.post(\"/transcript_through_video/\")\n",
        "def get_transcript_through_video(video_file: Optional[UploadFile] = File(None)):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        video_file: video file to be uploaded, mp4 or ts\n",
        "\n",
        "    function: \n",
        "        this function will accept a video, run ocr on the video, get the top keywords, send them to speech_to_text, return the transcript.\n",
        "    \"\"\"\n",
        "    print(type(video_file))\n",
        "    keywords = []\n",
        "\n",
        "    # transcript, _ =  get_transcript(input_file = video_file, words_list = keywords )\n",
        "    # return transcript\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8081)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "# if __name__ == \"__main__\":\n",
        "uvicorn.run(app, host='0.0.0.0', port=8081)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5znG2jdWjaSr"
      },
      "outputs": [],
      "source": [
        "a = {'india': {'ad_number': 0, 'frame_no': '4', 'max_area': 2117, 'best_position': (326, 618, 29, 73), 'freq_eng': 5.04, 'frames_count': 4, 'placement': 'Left', 'Placement_score': 4, 'IoU': 0.005915952672378621, 'count': 12, 'Count_score': 576, 'Max_Area_score': 21, 'Total_score': 601, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'coal': {'ad_number': 0, 'frame_no': '4', 'max_area': 2325, 'best_position': (972, 616, 31, 75), 'freq_eng': 4.49, 'frames_count': 4, 'placement': 'Out Of Range', 'Placement_score': 0, 'IoU': 0, 'count': 9, 'Count_score': 324, 'Max_Area_score': 23, 'Total_score': 347, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'power': {'ad_number': 0, 'frame_no': '4', 'max_area': 3131, 'best_position': (605, 615, 31, 101), 'freq_eng': 5.52, 'frames_count': 4, 'placement': 'Middle', 'Placement_score': 115, 'IoU': 0.0966358024691358, 'count': 7, 'Count_score': 196, 'Max_Area_score': 31, 'Total_score': 342, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'running': {'ad_number': 0, 'frame_no': '4', 'max_area': 5587, 'best_position': (538, 566, 37, 151), 'freq_eng': 5.23, 'frames_count': 1, 'placement': 'Middle', 'Placement_score': 154, 'IoU': 0.12861726781151583, 'count': 1, 'Count_score': 4, 'Max_Area_score': 55, 'Total_score': 213, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'blackouts': {'ad_number': 0, 'frame_no': '2', 'max_area': 8931, 'best_position': (828, 564, 39, 229), 'freq_eng': 2.9, 'frames_count': 3, 'placement': 'Right', 'Placement_score': 76, 'IoU': 0.10881287726358149, 'count': 3, 'Count_score': 36, 'Max_Area_score': 89, 'Total_score': 201, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'faces': {'ad_number': 0, 'frame_no': '3', 'max_area': 4551, 'best_position': (434, 566, 37, 123), 'freq_eng': 4.59, 'frames_count': 3, 'placement': 'Left', 'Placement_score': 98, 'IoU': 0.14046296296296296, 'count': 3, 'Count_score': 36, 'Max_Area_score': 45, 'Total_score': 179, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'cuts,': {'ad_number': 0, 'frame_no': '3', 'max_area': 4633, 'best_position': (708, 566, 41, 113), 'freq_eng': 4.42, 'frames_count': 3, 'placement': 'Right', 'Placement_score': 57, 'IoU': 0.08270962460530933, 'count': 3, 'Count_score': 36, 'Max_Area_score': 46, 'Total_score': 139, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'wion': {'ad_number': 0, 'frame_no': '2', 'max_area': 1407, 'best_position': (166, 628, 21, 67), 'freq_eng': 1.27, 'frames_count': 5, 'placement': 'Out Of Range', 'Placement_score': 0, 'IoU': 0, 'count': 5, 'Count_score': 100, 'Max_Area_score': 14, 'Total_score': 114, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'supply': {'ad_number': 0, 'frame_no': '2', 'max_area': 3007, 'best_position': (836, 616, 31, 97), 'freq_eng': 4.81, 'frames_count': 2, 'placement': 'Right', 'Placement_score': 64, 'IoU': 0.09176405291233695, 'count': 2, 'Count_score': 16, 'Max_Area_score': 30, 'Total_score': 110, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'meets': {'ad_number': 0, 'frame_no': '4', 'max_area': 2945, 'best_position': (404, 616, 31, 95), 'freq_eng': 4.36, 'frames_count': 2, 'placement': 'Left', 'Placement_score': 63, 'IoU': 0.09089506172839507, 'count': 2, 'Count_score': 16, 'Max_Area_score': 29, 'Total_score': 108, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'demand': {'ad_number': 0, 'frame_no': '4', 'max_area': 3689, 'best_position': (711, 615, 31, 119), 'freq_eng': 4.84, 'frames_count': 2, 'placement': 'Right', 'Placement_score': 50, 'IoU': 0.07181253898013128, 'count': 2, 'Count_score': 16, 'Max_Area_score': 36, 'Total_score': 102, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'weeks': {'ad_number': 0, 'frame_no': '1', 'max_area': 3007, 'best_position': (738, 616, 31, 97), 'freq_eng': 5.19, 'frames_count': 2, 'placement': 'Right', 'Placement_score': 54, 'IoU': 0.07836389108850582, 'count': 2, 'Count_score': 16, 'Max_Area_score': 30, 'Total_score': 100, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'fast': {'ad_number': 0, 'frame_no': '4', 'max_area': 2997, 'best_position': (454, 566, 37, 81), 'freq_eng': 5.13, 'frames_count': 1, 'placement': 'Left', 'Placement_score': 64, 'IoU': 0.0925, 'count': 1, 'Count_score': 4, 'Max_Area_score': 29, 'Total_score': 97, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'plant': {'ad_number': 0, 'frame_no': '2', 'max_area': 2573, 'best_position': (468, 616, 31, 83), 'freq_eng': 4.89, 'frames_count': 2, 'placement': 'Left', 'Placement_score': 55, 'IoU': 0.07941358024691358, 'count': 2, 'Count_score': 16, 'Max_Area_score': 25, 'Total_score': 96, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'crunch': {'ad_number': 0, 'frame_no': '4', 'max_area': 2231, 'best_position': (474, 536, 23, 97), 'freq_eng': 3.66, 'frames_count': 4, 'placement': 'Left', 'Placement_score': 1, 'IoU': 0.0028088260844385243, 'count': 4, 'Count_score': 64, 'Max_Area_score': 22, 'Total_score': 87, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}, 'stocks': {'ad_number': 0, 'frame_no': '4', 'max_area': 5265, 'best_position': (910, 563, 39, 135), 'freq_eng': 4.28, 'frames_count': 1, 'placement': 'Right', 'Placement_score': 16, 'IoU': 0.023310783274920532, 'count': 1, 'Count_score': 4, 'Max_Area_score': 52, 'Total_score': 72, 'is_present_in_video_url': None, 'is_present_in_url_database': False, 'is_entity': False}}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMP-snAkjaSz"
      },
      "outputs": [],
      "source": [
        "!curl -o logo.png https://colab.research.google.com/img/colab_favicon_256px.png\n",
        "import cv2\n",
        "img = cv2.imread('logo.png', cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lSAMjSHgcwz",
        "outputId": "f0155d19-b710-49b4-a893-b46c90d3dd79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "india\n",
            "coal\n",
            "power\n",
            "running\n",
            "blackouts\n",
            "faces\n",
            "cuts,\n",
            "wion\n",
            "supply\n",
            "meets\n",
            "demand\n",
            "weeks\n",
            "fast\n",
            "plant\n",
            "crunch\n",
            "stocks\n"
          ]
        }
      ],
      "source": [
        "for key in a:\n",
        "    print(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayPugnc1x1t5",
        "outputId": "7e3d8cfd-64be-4de0-ac76-950d8aaa83b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final_main.py\t     README.md\t       speech_to_text.py  text_recognition\n",
            "metadata_extraction  requirements.txt  temp.mp4\n"
          ]
        }
      ],
      "source": [
        "!rm -r __pycache__ __init__.py .git .gitignore\n",
        "!ls -a"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pytrends"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvjVdrzzj59m",
        "outputId": "a91b022f-107c-4018-b027-7f0debfa4308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytrends\n",
            "  Downloading pytrends-4.7.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from pytrends) (1.1.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pytrends) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytrends) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25->pytrends) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytrends) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytrends) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytrends) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytrends) (1.24.3)\n",
            "Installing collected packages: pytrends\n",
            "Successfully installed pytrends-4.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytrends.request import TrendReq\n",
        "pytrends = TrendReq(hl='en-US', tz=360 , )"
      ],
      "metadata": {
        "id": "KYFmPEzQksen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kw_list = [\"fightcamp.com\"]\n",
        "pytrends.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='', gprop='')"
      ],
      "metadata": {
        "id": "lmhGw4lXmplH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword = \"fightcamp.com\"\n",
        "pytrends.suggestions(keyword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPFJxswIj8Ru",
        "outputId": "5ce778d6-37fc-4953-ff82-d4e6c6f0bd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'mid': '/g/11jgg8y33r', 'title': 'FightCamp', 'type': 'Topic'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytrends.related_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZVu8JWskKT5",
        "outputId": "78dbdd16-f7ff-4bc9-8bca-cf260255413e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fightcamp.com': {'rising':      value formattedValue  ... topic_title topic_type\n",
              "  0  2503500       Breakout  ...   FightCamp      Topic\n",
              "  \n",
              "  [1 rows x 6 columns],\n",
              "  'top':    value formattedValue  hasData  ...      topic_mid topic_title topic_type\n",
              "  0    100            100     True  ...  /g/11jgg8y33r   FightCamp      Topic\n",
              "  \n",
              "  [1 rows x 7 columns]}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjfrnrRGVR6v",
        "outputId": "236bec6c-34f9-4a6f-f536-825159e03066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-11.0.2-py3-none-any.whl (56 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▉                          | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 20 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 30 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 40 kB 3.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 51 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 56 kB 1.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-11.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the module\n",
        "from pytube import YouTube\n",
        "\n",
        "# where to save\n",
        "SAVE_PATH = \"\" #to_do\n",
        "\n",
        "# link of the video to be downloaded\n",
        "link=\"https://youtu.be/8cggkMHUMgA\"\n",
        "\n",
        "try:\n",
        "\t# object creation using YouTube\n",
        "\t# which was imported in the beginning\n",
        "\tyt = YouTube(link)\n",
        "except:\n",
        "\tprint(\"Connection Error\") #to handle exception\n",
        "\n",
        "# filters out all the files with \"mp4\" extension\n",
        "mp4files = yt.filter('mp4')\n",
        "\n",
        "#to set the name of the file\n",
        "yt.set_filename('temp')\n",
        "\n",
        "# get the video with the extension and\n",
        "# resolution passed in the get() function\n",
        "d_video = yt.get(mp4files[-1].extension,mp4files[-1].resolution)\n",
        "try:\n",
        "\t# downloading the video\n",
        "\td_video.download(SAVE_PATH)\n",
        "except:\n",
        "\tprint(\"Some Error!\")\n",
        "print('Task Completed!')\n",
        "\n"
      ],
      "metadata": {
        "id": "kKeJFUy2l81U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "#yt = YouTube(link)\n",
        "YouTube(link).streams.first().download('/content/')"
      ],
      "metadata": {
        "id": "ci_jzwQhVi-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade youtube-dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmmIyI_-cn0C",
        "outputId": "6116b5c5-a1e3-4ea0-cfe9-233d8d41aabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-dl in /usr/local/lib/python3.7/dist-packages (2021.12.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "link = 'https://youtu.be/8cggkMHUMgA'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKDDmtrCdGbh",
        "outputId": "25604147-c507-47a8-fe70-5e07eaff3c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] 8cggkMHUMgA: Downloading webpage\n",
            "[youtube] 8cggkMHUMgA: Downloading MPD manifest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Requested formats are incompatible for merge and will be merged into mkv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Cisco Security Product Portfolio in 5 Minutes-8cggkMHUMgA.mkv has already been downloaded and merged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y swig3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9dC5hEkWUbB",
        "outputId": "77225a73-bdec-4130-f12f-57cfc7051259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig3.0\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,094 kB of archives.\n",
            "After this operation, 5,499 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Fetched 1,094 kB in 1s (1,246 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 155229 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install jamspell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2BqHQ5zWEt_",
        "outputId": "a2194877-14bb-4fe3-dc2b-bb28c3175025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jamspell\n",
            "  Using cached jamspell-0.0.12.tar.gz (174 kB)\n",
            "Building wheels for collected packages: jamspell\n",
            "  Building wheel for jamspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jamspell: filename=jamspell-0.0.12-cp37-cp37m-linux_x86_64.whl size=1347647 sha256=a4b9a1812b5d83ac27b5efb94354bb310bb4c32c0c985b18429e879da2ed8041\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/df/9c/9b335e69aa0f28e7f508ec0ebefadcc703f168beb52ae7ebe7\n",
            "Successfully built jamspell\n",
            "Installing collected packages: jamspell\n",
            "Successfully installed jamspell-0.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf /content/en.tar.gz"
      ],
      "metadata": {
        "id": "_WSNFToWtGO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jamspell\n",
        "\n",
        "corrector = jamspell.TSpellCorrector()\n",
        "corrector.LoadLangModel('/content/en.bin')\n",
        "\n",
        "corrector.FixFragment('I am the begt spell cherken!')\n",
        "# u'I am the best spell checker!'\n",
        "\n",
        "corrector.GetCandidates(['i', 'am', 'the', 'begt', 'spell', 'cherken'], 3)\n",
        "# (u'best', u'beat', u'belt', u'bet', u'bent', ... )\n",
        "\n",
        "corrector.GetCandidates(['i', 'am', 'the', 'begt', 'spell', 'cherken'], 5)\n",
        "# (u'checker', u'chicken', u'checked', u'wherein', u'coherent', ...)"
      ],
      "metadata": {
        "id": "ivqEZJzvWJKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_to_correct = \"-- youtoo TM AMERICA -- we blames trauma for assault /n youtoo CLUB esunians /n How do you /n charges Tell ban hostage /n York Post /n voke /n Pall /n a /n alter Trump /n Just $5.95/mo. /n Post /n Chanper Ander /n Shows. /n GetOur Free: E-Newsletter: /n youtoo /n big deal /n DONT BLINK /n SIGN up for OUR ENEWSLETTER! /n Da lime /n 12:00:01 /n Facebook Feed /n Feed /n Primetime Uneup /n 7:00 PM CI /n amarks. shared Coop /n Friday December: 29th, /n unuted Dreams post /n this Sunday Dontamiss Coops. for Troops your local stations /n WWW /n eanower /n 8:00: /n Eriday, December: -- YOUTOO AMERICA a MONTHLY NEWSLETTER II JANUARY 2018 /n youtoo AMERICA y /n Red, White and YOU! /n WWW. /n accm /n nonit -- each /n in this weekly tv series each /n features a veterans story of service and /n sacrifice. Their challenges upon retuming home. /n And. the of therapy /n chickens and a coop! /n WATCH PROMO HERE /n youtoo go AMERICA /n Go, YoutooAmerica. com /n Take Youtoo America with you on the GOI /n go /n Now you can watch live and on demand /n content on any device by simply /n Go. YoutcoAmerica. going to com using internet browser. any /n yourco -- COFFEE /n MERICA /n RED, WHITE AND TALK! /n go.youtod me /n Lines: -- inn NEWS /n and /n an /n go.youtocamerica.com/n aboutus /n shows /n contact /n youtoo GO /n pollowus --\"\n",
        "#sentence_to_correct = sentence_to_correct.replace()\n",
        "corrector.FixFragment(sentence_to_correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "mRtFeptHu2tV",
        "outputId": "8d35028a-e59f-4d66-f7f8-060169221540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-- youth TO AMERICA -- we blames trauma for assault /n youth CLUB lesbians /n How do you /n charges Tell ban hostage /n York Post /n vote /n Pall /n a /n alter Trump /n Just $5.95/mo. /n Post /n Changer Ander /n Shows. /n DetOur Free: E-Newsletter: /n youth /a big deal /n DONT BLINK /n SIGN up for OUR NEWSLETTER! /n Da lime /n 12:00:01 /n Facebook Feed /n Feed /n Primetime Unep /n 7:00 PM CI /n marks. shared Coop /n Friday December: 29th, /n united Dreams post /in this Sunday Dontamiss Corps. for Troops your local stations /n WWW /n another /n 8:00: /n Friday, December: -- OUTLOOK AMERICA a MONTHLY NEWSLETTER II JANUARY 2018 /n youth AMERICA y /n Red, White and YOU! /n WWW. /n acc /n nonit -- each /n in this weekly tv series each /n features a veterans story of service and /a sacrifice. Their challenges upon resuming home. /n And. the of therapy /n chickens and a coop! /n WATCH PROMO HERE /n youth go AMERICA /n Go, YoutooAmerica. com /n Take Youth America with you on the GO /n go /n Now you can watch live and on demand /n content on any device by simply /n Go. YoutcoAmerica. going to com using internet browser. any /n your -- COFFEE /n MERICA /n RED, WHITE AND TALK! /n go.youth me /n Lines: -- in NEWS /n and /n an /n go.youtocamerica.com/n about /n shows /n contact /n youth GO /n follows --'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAQkRzaHzSfm",
        "outputId": "2d6e8412-93e2-4379-b17c-12512cb00239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra code"
      ],
      "metadata": {
        "id": "FU4OPe3N2a23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LbVNeUaCu_u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwcnVQpooY_m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_companyname(bty_soup_obj):\n",
        "    '''Extract company name from url by parsing the html and extracting the text from the company name tag'''\n",
        "    try:\n",
        "        #page = requests.get(url)\n",
        "        #soup = BeautifulSoup(page.content, 'html.parser')\n",
        "        company_name = bty_soup_obj.find('h1', attrs={'class': 'company-name'}).text\n",
        "        print(company_name)\n",
        "        return company_name\n",
        "    except Exception as er:\n",
        "        #print(f\"error occured error is: {er}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "lOojEz6Z3dhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_title(bty_soup_obj):\n",
        "    titles = list()\n",
        "    try:\n",
        "        for title in soup.find_all('title'):\n",
        "            titles.append(title.get_text())\n",
        "    except:\n",
        "        pass\n",
        "    return titles"
      ],
      "metadata": {
        "id": "MQDvBNrY4XUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def hit_n_return_bty_obj(url_to_check):\n",
        "    try:\n",
        "        if 'http' not in url_to_check:\n",
        "            url_to_check = 'https://' + url_to_check \n",
        "\n",
        "        headers = {\"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36\"}\n",
        "        res = requests.get( url_to_check , timeout= 10 , allow_redirects = True , headers = headers , verify = False)\n",
        "        soup_obj = BeautifulSoup(res.content, \"html.parser\")\n",
        "    \n",
        "    except Exception as er:\n",
        "        print(f\"error occured while trying to hit the url , error is: {er}\")\n",
        "        return ''\n",
        "    \n",
        "    return soup_obj\n"
      ],
      "metadata": {
        "id": "IFOYwaUu4zY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hit_n_return_bty_obj('https://www.manageyourbp.org')"
      ],
      "metadata": {
        "id": "VFP9XnI0IAzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text( bty_soup_obj ):\n",
        "    #return text found the url , using bty soup object\n",
        "    text = \"\"\n",
        "    try:\n",
        "        paragraphs = bty_soup_obj.find_all('p')\n",
        "        for p in paragraphs:\n",
        "            text = text + \" \" + p.text\n",
        "\n",
        "        #print(\"after para\")\n",
        "        #check for headings and add them \n",
        "        heading_tags = [\"h1\", \"h2\", \"h3\"]\n",
        "        headings = bty_soup_obj.find_all(heading_tags)\n",
        "        for p in headings:\n",
        "            text = text + \" \" + p.text\n",
        "        \n",
        "        #print(\"after headings\")\n",
        "        #if text is still empty check for ul tags \n",
        "        if text==\"\":\n",
        "            points = bty_soup_obj.find_all('li')\n",
        "            for p in points:\n",
        "                text = text + \" \" + p.text\n",
        "\n",
        "    except Exception as er:\n",
        "        print(f\"error occured (extract_text) error is: {er}\")\n",
        "        pass\n",
        "    \n",
        "    return text\n"
      ],
      "metadata": {
        "id": "FmTfqFE5NoBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_info(url_to_check):\n",
        "    \n",
        "    #return dict with organisation , title and ad type\n",
        "    text = ''\n",
        "    response_dict = dict()\n",
        "    try:\n",
        "        \n",
        "        #hit the url and get the soup_obj\n",
        "        soup_obj = hit_n_return_bty_obj( url_to_check = url_to_check )\n",
        "\n",
        "        #if soup object is empty return empty dictionary \n",
        "        if not soup_obj:\n",
        "            return {}\n",
        "\n",
        "        \n",
        "        #get org name \n",
        "        orginsation = extract_companyname(bty_soup_obj = soup_obj )\n",
        "\n",
        "        #Get Title \n",
        "        title = extract_title( bty_soup_obj = soup_obj )\n",
        "        \n",
        "        #get the text \n",
        "        #summarise the text https://www.analyticsvidhya.com/blog/2020/12/tired-of-reading-long-articles-text-summarization-will-make-your-task-easier/\n",
        "        text = extract_text( bty_soup_obj = soup_obj )\n",
        "    \n",
        "    except Exception as er:\n",
        "        print(f\"error occured(return_info) , error is: {er}\")\n",
        "    \n",
        "    return text\n"
      ],
      "metadata": {
        "id": "c-F9j7lVbEnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "json_file_path = '/content/all_urls_text.json'\n",
        "with open(json_file_path , 'r') as jfp:\n",
        "    j_data =  json.load(jfp)\n"
      ],
      "metadata": {
        "id": "XgjONYEQ5GuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_processed = []\n",
        "for ky in j_data:\n",
        "    if j_data[ky]=='' or j_data[ky]=='{}' or j_data[ky]==' 403 Forbidden':\n",
        "        text = return_info( url_to_check = ky )\n",
        "        j_data[ky] = text\n",
        "        not_processed.append(ky)\n",
        "\n",
        "print(len(not_processed))\n",
        "\n",
        "with open(json_file_path , 'w') as jfp:\n",
        "    json.dump(j_data , jfp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fGETsFk5RRg",
        "outputId": "25fa9958-4931-4a9a-c14b-2828641ba0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-CyIOuo4-xC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ads_csv_sheet = '/content/drive/MyDrive/key_words/Creative Master List 2-4-21.xlsx'\n",
        "ads_data = pd.read_excel(ads_csv_sheet)"
      ],
      "metadata": {
        "id": "iebpg_wt7gwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(ads_data['url']))"
      ],
      "metadata": {
        "id": "WV_-TxNhEluO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sparknlp pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaUe0z3gxhXb",
        "outputId": "5a0287f5-e769-4612-90fb-59ee527fd9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sparknlp in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spark-nlp in /usr/local/lib/python3.7/dist-packages (from sparknlp) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sparknlp) (1.19.5)\n",
            "Collecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 52.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=79495241bed68354afe66c4182162c3559ab37557d13ab4653926aa5238aaad1\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.pretrained import PretrainedPipelinein\n",
        "pipeline = PretrainedPipelinein('check_spelling', lang = 'en')\n",
        "annotations =  pipeline.fullAnnotate(\"youtocamerica is the site\")[0]\n",
        "annotations.keys()"
      ],
      "metadata": {
        "id": "XMru-VKdEpUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install nlu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm3Tr3QfySIP",
        "outputId": "d7d7511b-3969-47b7-b5f9-d9d7108c9bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nlu in /usr/local/lib/python3.7/dist-packages (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlu) (1.19.5)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlu) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlu) (1.3.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from nlu) (0.6)\n",
            "Requirement already satisfied: spark-nlp<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from nlu) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlu) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlu) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->nlu) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "json_path = \"/content/drive/MyDrive/all_urls_text.json\"\n",
        "with open(json_path , 'r') as jfp:\n",
        "    j_data = json.load(jfp)"
      ],
      "metadata": {
        "id": "ktO-ewNJyOkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_processed = set()\n",
        "for ky in j_data:\n",
        "    if j_data[ky]=='' or j_data[ky]=='{}' or j_data[ky]==' 403 Forbidden':\n",
        "        not_processed.add(ky)\n",
        "\n",
        "print(len(not_processed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpeC8ocDdXJi",
        "outputId": "e6fedb05-0186-4c31-8b63-0476fbf2e36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def pre_process_text(text_passed):\n",
        "    text = text_passed.replace(\"\\n\",\"\").replace(\"/n\",\"\").replace(\"/t\",\"\").replace(\"\\t\",\"\")\n",
        "    text = re.sub('[^A-Za-z0-9]', ' ', text)\n",
        "    text = re.sub(' +', ' ', text )\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "qj0kAu6ydmMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_processed = set()\n",
        "new_j_data = dict(j_data)\n",
        "for ky in j_data:\n",
        "    if j_data[ky]=='' or j_data[ky]=='{}' or j_data[ky]==' 403 Forbidden':\n",
        "        not_processed.add(ky)\n",
        "        del new_j_data[ky]\n",
        "    else:\n",
        "        j_data[ky] = pre_process_text( text_passed = j_data[ky] )\n"
      ],
      "metadata": {
        "id": "HEaINnpki1-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_j_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PgePk-njQzn",
        "outputId": "9722c409-abbb-4fc8-c90e-58c2d60a3bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9170"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_j_data['urls_list'] = list(not_processed)"
      ],
      "metadata": {
        "id": "KNa5Lv1Yna2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_j_data['urls_list']"
      ],
      "metadata": {
        "id": "FWHv1-ZwuO2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('filtered_ad_data.json','w') as jfp:\n",
        "    json.dump(new_j_data,jfp)"
      ],
      "metadata": {
        "id": "L5hui3s2u2S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/all_urls_text.json /content/drive/MyDrive/key_words"
      ],
      "metadata": {
        "id": "K5C-Ysevv7ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QpDJn3qRwlIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Speech_to_text_api.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}